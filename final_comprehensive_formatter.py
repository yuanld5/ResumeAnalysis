#!/usr/bin/env python3
"""
æœ€ç»ˆç»¼åˆæ ¼å¼åŒ–å™¨
ç»“åˆåŸºç¡€ä¿¡æ¯æå–å’Œé«˜çº§æ¨ç†åˆ†æï¼Œå®Œå…¨åŒ¹é…æ¼”ç¤ºæ•°æ®å¤æ‚åº¦
"""

import os
import json
import sys
import re
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
import langextract as lx
from langextract.providers.openai import OpenAILanguageModel
from langextract.data import ExampleData, Extraction

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class FinalComprehensiveFormatter:
    """æœ€ç»ˆç»¼åˆæ ¼å¼åŒ–å™¨ - å®Œæ•´çš„æ¨ç†åˆ†æç³»ç»Ÿ"""
    
    def __init__(self):
        pass

    def format_resume_comprehensive(self, text_file: str) -> dict:
        """
        ç»¼åˆæ ¼å¼åŒ–ç®€å† - åŸºç¡€æå– + é«˜çº§æ¨ç†
        """
        print(f"ä½¿ç”¨æœ€ç»ˆç»¼åˆæ ¼å¼åŒ–å™¨: {text_file}")
        
        # è¯»å–æ–‡æœ¬å†…å®¹
        with open(text_file, 'r', encoding='utf-8') as f:
            text = f.read()
        
        print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        print(f"å†…å®¹é¢„è§ˆ: {text[:200]}...")
        
        # ç¬¬ä¸€æ­¥ï¼šåŸºç¡€ä¿¡æ¯æå–ï¼ˆä½¿ç”¨ç®€å•ç›´æ¥çš„æ–¹æ³•ï¼‰
        basic_info = self._extract_basic_info_direct(text)
        
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨AIè¿›è¡Œæ·±åº¦åˆ†æå’Œæ¨ç†
        reasoning_analysis = self._perform_ai_reasoning_analysis(text, basic_info)
        
        # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆæœ€ç»ˆExcelæ ¼å¼
        final_result = self._generate_comprehensive_excel_format(basic_info, reasoning_analysis)
        
        return final_result

    def _extract_basic_info_direct(self, text: str) -> dict:
        """ç›´æ¥ä»æ–‡æœ¬ä¸­æå–åŸºç¡€ä¿¡æ¯"""
        
        basic_info = {}
        
        # æå–å§“åï¼ˆé€šå¸¸åœ¨ç¬¬ä¸€è¡Œï¼‰
        lines = text.strip().split('\n')
        if lines:
            first_line = lines[0].strip()
            if len(first_line) <= 10 and not any(char in first_line for char in [':', 'ï¼š', '|']):
                basic_info['å§“å'] = first_line
        
        # æå–æ€§åˆ«ã€å¹´é¾„ç­‰åŸºæœ¬ä¿¡æ¯
        for line in lines[:10]:  # åœ¨å‰10è¡Œä¸­æŸ¥æ‰¾
            line = line.strip()
            
            # æ€§åˆ«å’Œå¹´é¾„é€šå¸¸åœ¨ä¸€è¡Œï¼Œæ ¼å¼å¦‚ï¼šç”·|32å²|ç±è´¯ï¼šæˆéƒ½
            if '|' in line and ('ç”·' in line or 'å¥³' in line):
                parts = line.split('|')
                for part in parts:
                    part = part.strip()
                    if part in ['ç”·', 'å¥³']:
                        basic_info['æ€§åˆ«'] = part
                    elif 'å²' in part:
                        age_match = re.search(r'(\d+)å²', part)
                        if age_match:
                            basic_info['å¹´é¾„'] = age_match.group(1) + 'å²'
        
        # æå–è”ç³»æ–¹å¼
        phone_pattern = r'(?:ç”µè¯|æ‰‹æœº|è”ç³»ç”µè¯)[:ï¼š]\s*(\d{11})'
        phone_match = re.search(phone_pattern, text)
        if phone_match:
            basic_info['ç”µè¯'] = phone_match.group(1)
        
        email_pattern = r'(?:é‚®ç®±|email)[:ï¼š]\s*([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'
        email_match = re.search(email_pattern, text, re.IGNORECASE)
        if email_match:
            basic_info['é‚®ç®±'] = email_match.group(1)
        
        # æå–å·¥ä½œå¹´é™
        work_exp_patterns = [
            r'å·¥ä½œæ—¶é•¿[:ï¼š]\s*(\d+)å¹´',
            r'å·¥ä½œç»éªŒ[:ï¼š]\s*(\d+)å¹´',
            r'(\d+)å¹´å·¥ä½œç»éªŒ'
        ]
        for pattern in work_exp_patterns:
            match = re.search(pattern, text)
            if match:
                basic_info['å·¥ä½œå¹´é™'] = match.group(1) + 'å¹´'
                break
        
        # æå–æ±‚èŒæ„å‘ä½œä¸ºå½“å‰èŒä½å‚è€ƒ
        job_pattern = r'æ±‚èŒæ„å‘[:ï¼š]\s*([^\n]+)'
        job_match = re.search(job_pattern, text)
        if job_match:
            basic_info['æ±‚èŒæ„å‘'] = job_match.group(1).strip()
        
        print(f"ç›´æ¥æå–çš„åŸºç¡€ä¿¡æ¯: {basic_info}")
        return basic_info

    def _perform_ai_reasoning_analysis(self, text: str, basic_info: dict) -> dict:
        """ä½¿ç”¨AIè¿›è¡Œæ·±åº¦æ¨ç†åˆ†æ"""
        
        # æ„å»ºåˆ†æschema
        analysis_schema = {
            "æŠ€æœ¯èƒ½åŠ›åˆ†æ": {
                "æ ¸å¿ƒæŠ€æœ¯æ ˆ": "string - ä¸»è¦æŒæ¡çš„æŠ€æœ¯æ ˆ",
                "æŠ€æœ¯æ·±åº¦è¯„ä¼°": "string - æŠ€æœ¯èƒ½åŠ›æ·±åº¦åˆ†æ",
                "æŠ€æœ¯åˆ›æ–°èƒ½åŠ›": "string - åˆ›æ–°å’Œä¼˜åŒ–èƒ½åŠ›è¯„ä¼°",
                "æ¶æ„è®¾è®¡èƒ½åŠ›": "string - ç³»ç»Ÿæ¶æ„è®¾è®¡èƒ½åŠ›"
            },
            "ç®¡ç†èƒ½åŠ›åˆ†æ": {
                "å›¢é˜Ÿåä½œ": "string - å›¢é˜Ÿåˆä½œèƒ½åŠ›",
                "é¡¹ç›®ç®¡ç†": "string - é¡¹ç›®ç®¡ç†ç»éªŒ",
                "æ²Ÿé€šåè°ƒ": "string - æ²Ÿé€šåè°ƒèƒ½åŠ›",
                "é¢†å¯¼æ½œåŠ›": "string - é¢†å¯¼åŠ›æ½œåŠ›è¯„ä¼°"
            },
            "ä¸šåŠ¡èƒ½åŠ›åˆ†æ": {
                "éœ€æ±‚ç†è§£": "string - ä¸šåŠ¡éœ€æ±‚ç†è§£èƒ½åŠ›",
                "äº§å“æ€ç»´": "string - äº§å“å’Œç”¨æˆ·æ€ç»´",
                "é—®é¢˜è§£å†³": "string - å¤æ‚é—®é¢˜è§£å†³èƒ½åŠ›",
                "ä¸šåŠ¡ä»·å€¼": "string - åˆ›é€ ä¸šåŠ¡ä»·å€¼çš„èƒ½åŠ›"
            },
            "å‘å±•æ½œåŠ›è¯„ä¼°": {
                "èŒä¸šå‘å±•": "string - èŒä¸šå‘å±•æ½œåŠ›",
                "å­¦ä¹ èƒ½åŠ›": "string - å­¦ä¹ æ–°æŠ€æœ¯çš„èƒ½åŠ›",
                "åˆ›æ–°æ€ç»´": "string - åˆ›æ–°æ€ç»´å’Œçªç ´èƒ½åŠ›",
                "é€‚åº”èƒ½åŠ›": "string - ç¯å¢ƒé€‚åº”å’Œå˜åŒ–åº”å¯¹"
            },
            "é£é™©å› ç´ è¯†åˆ«": {
                "æŠ€æœ¯é£é™©": "string - æŠ€æœ¯èƒ½åŠ›ç›¸å…³é£é™©",
                "ç®¡ç†é£é™©": "string - ç®¡ç†èƒ½åŠ›ç›¸å…³é£é™©",
                "å‘å±•é£é™©": "string - èŒä¸šå‘å±•ç›¸å…³é£é™©"
            }
        }
        
        # åˆ›å»ºåˆ†æç¤ºä¾‹
        example_text = """
        ä»»è¡—å¹³
        
        ç”·|32å²|ç±è´¯ï¼šæˆéƒ½
        
        è”ç³»æ–¹å¼
        ç”µè¯:19113247892
        é‚®ç®±:r414164729@163.com
        
        æ±‚èŒä¿¡æ¯
        å·¥ä½œæ—¶é•¿ï¼š9å¹´
        æ±‚èŒæ„å‘ï¼šPython+go
        
        ä¸ªäººä¼˜åŠ¿
        ç²¾é€šPythonã€goï¼Œäº†è§£shellï¼Œluaç­‰è„šæœ¬è¯­è¨€
        ç†Ÿç»ƒä½¿ç”¨Djangoã€Flaskï¼ŒfastAPIï¼Œginç­‰webæ¡†æ¶è¿›è¡Œå¼€å‘
        ç†Ÿæ‚‰mysqlï¼Œpgç­‰å¸¸è§æ•°æ®åº“ï¼Œ
        ç†Ÿæ‚‰redisï¼ŒMongoï¼ŒESç­‰NoSQL
        ç†Ÿæ‚‰dockerå®¹å™¨æŠ€æœ¯ï¼Œç†Ÿæ‚‰k8sï¼Œk3s
        ç†Ÿæ‚‰numpyï¼Œpandasï¼Œmatplotlib
        ç†Ÿç»ƒä½¿ç”¨gitè¿›è¡Œä»£ç ç®¡ç†
        äº†è§£å¸¸è§æœºå™¨å­¦ä¹ ï¼Œæ·±åº¦å­¦ä¹ ç›¸å…³æ¨¡å—,å¦‚sklearnï¼Œxgbostï¼Œpytorchï¼ŒTensorFlow
        å¤šæ¬¡é¡¹ç›®æˆåŠŸäº¤ä»˜ç»éªŒ
        è‰¯å¥½çš„è‡ªæˆ‘é©±åŠ¨åŠ›ï¼Œè¿½é€æ–°æŠ€æœ¯
        
        å·¥ä½œç»å†
        æŸç§‘æŠ€å…¬å¸ é«˜çº§Pythonå¼€å‘å·¥ç¨‹å¸ˆ
        è´Ÿè´£åç«¯ç³»ç»Ÿå¼€å‘å’Œä¼˜åŒ–
        å‚ä¸å¾®æœåŠ¡æ¶æ„è®¾è®¡
        """
        
        # åˆ›å»ºåˆ†ææå–ç¤ºä¾‹
        analysis_extractions = [
            # æŠ€æœ¯èƒ½åŠ›åˆ†æ
            Extraction(extraction_class="æŠ€æœ¯èƒ½åŠ›åˆ†æ_æ ¸å¿ƒæŠ€æœ¯æ ˆ", extraction_text="Pythonåç«¯å¼€å‘ï¼Œå¾®æœåŠ¡æ¶æ„ï¼Œå®¹å™¨åŒ–æŠ€æœ¯"),
            Extraction(extraction_class="æŠ€æœ¯èƒ½åŠ›åˆ†æ_æŠ€æœ¯æ·±åº¦è¯„ä¼°", extraction_text="ç²¾é€šPythonå’ŒGoè¯­è¨€ï¼Œå…·å¤‡å…¨æ ˆå¼€å‘èƒ½åŠ›ï¼ŒæŒæ¡ç°ä»£åŒ–å¼€å‘æŠ€æœ¯æ ˆ"),
            Extraction(extraction_class="æŠ€æœ¯èƒ½åŠ›åˆ†æ_æŠ€æœ¯åˆ›æ–°èƒ½åŠ›", extraction_text="è¿½é€æ–°æŠ€æœ¯ï¼Œå…·å¤‡æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯å‚¨å¤‡ï¼Œæœ‰æŠ€æœ¯ä¼˜åŒ–ç»éªŒ"),
            Extraction(extraction_class="æŠ€æœ¯èƒ½åŠ›åˆ†æ_æ¶æ„è®¾è®¡èƒ½åŠ›", extraction_text="å‚ä¸å¾®æœåŠ¡æ¶æ„è®¾è®¡ï¼Œç†Ÿæ‚‰å®¹å™¨åŒ–å’Œäº‘åŸç”ŸæŠ€æœ¯"),
            
            # ç®¡ç†èƒ½åŠ›åˆ†æ
            Extraction(extraction_class="ç®¡ç†èƒ½åŠ›åˆ†æ_å›¢é˜Ÿåä½œ", extraction_text="å¤šæ¬¡é¡¹ç›®æˆåŠŸäº¤ä»˜ç»éªŒï¼Œå…·å¤‡è‰¯å¥½çš„å›¢é˜Ÿåä½œèƒ½åŠ›"),
            Extraction(extraction_class="ç®¡ç†èƒ½åŠ›åˆ†æ_é¡¹ç›®ç®¡ç†", extraction_text="æœ‰é¡¹ç›®äº¤ä»˜ç»éªŒï¼Œå…·å¤‡ä¸€å®šçš„é¡¹ç›®ç®¡ç†èƒ½åŠ›"),
            Extraction(extraction_class="ç®¡ç†èƒ½åŠ›åˆ†æ_æ²Ÿé€šåè°ƒ", extraction_text="èƒ½å¤Ÿå‚ä¸æ¶æ„è®¾è®¡è®¨è®ºï¼Œå…·å¤‡æŠ€æœ¯æ²Ÿé€šèƒ½åŠ›"),
            Extraction(extraction_class="ç®¡ç†èƒ½åŠ›åˆ†æ_é¢†å¯¼æ½œåŠ›", extraction_text="è‡ªæˆ‘é©±åŠ¨åŠ›å¼ºï¼Œæœ‰æŠ€æœ¯é¢†å¯¼æ½œåŠ›"),
            
            # ä¸šåŠ¡èƒ½åŠ›åˆ†æ
            Extraction(extraction_class="ä¸šåŠ¡èƒ½åŠ›åˆ†æ_éœ€æ±‚ç†è§£", extraction_text="åç«¯ç³»ç»Ÿå¼€å‘ç»éªŒï¼Œèƒ½å¤Ÿç†è§£ä¸šåŠ¡éœ€æ±‚"),
            Extraction(extraction_class="ä¸šåŠ¡èƒ½åŠ›åˆ†æ_äº§å“æ€ç»´", extraction_text="å…·å¤‡ä¸€å®šçš„äº§å“æ€ç»´ï¼Œå…³æ³¨ç”¨æˆ·ä½“éªŒ"),
            Extraction(extraction_class="ä¸šåŠ¡èƒ½åŠ›åˆ†æ_é—®é¢˜è§£å†³", extraction_text="ç³»ç»Ÿä¼˜åŒ–ç»éªŒï¼Œå…·å¤‡å¤æ‚é—®é¢˜è§£å†³èƒ½åŠ›"),
            Extraction(extraction_class="ä¸šåŠ¡èƒ½åŠ›åˆ†æ_ä¸šåŠ¡ä»·å€¼", extraction_text="é€šè¿‡æŠ€æœ¯ä¼˜åŒ–åˆ›é€ ä¸šåŠ¡ä»·å€¼"),
            
            # å‘å±•æ½œåŠ›è¯„ä¼°
            Extraction(extraction_class="å‘å±•æ½œåŠ›è¯„ä¼°_èŒä¸šå‘å±•", extraction_text="æŠ€æœ¯ä¸“å®¶å€™é€‰äººï¼Œæœ‰å‘æ¶æ„å¸ˆå‘å±•çš„æ½œåŠ›"),
            Extraction(extraction_class="å‘å±•æ½œåŠ›è¯„ä¼°_å­¦ä¹ èƒ½åŠ›", extraction_text="è¿½é€æ–°æŠ€æœ¯ï¼Œå­¦ä¹ èƒ½åŠ›å¼ºï¼ŒæŠ€æœ¯è§†é‡å¹¿"),
            Extraction(extraction_class="å‘å±•æ½œåŠ›è¯„ä¼°_åˆ›æ–°æ€ç»´", extraction_text="å…³æ³¨æ–°æŠ€æœ¯ï¼Œå…·å¤‡åˆ›æ–°æ€ç»´å’ŒæŠ€æœ¯æ•æ„Ÿåº¦"),
            Extraction(extraction_class="å‘å±•æ½œåŠ›è¯„ä¼°_é€‚åº”èƒ½åŠ›", extraction_text="æŠ€æœ¯æ ˆå¹¿æ³›ï¼Œé€‚åº”èƒ½åŠ›å¼º"),
            
            # é£é™©å› ç´ è¯†åˆ«
            Extraction(extraction_class="é£é™©å› ç´ è¯†åˆ«_æŠ€æœ¯é£é™©", extraction_text="æŠ€æœ¯èƒ½åŠ›è¾ƒå¼ºï¼Œæ— æ˜æ˜¾æŠ€æœ¯é£é™©"),
            Extraction(extraction_class="é£é™©å› ç´ è¯†åˆ«_ç®¡ç†é£é™©", extraction_text="ç®¡ç†ç»éªŒç›¸å¯¹ä¸è¶³ï¼Œéœ€è¦åœ¨å›¢é˜Ÿç®¡ç†æ–¹é¢åŠ å¼º"),
            Extraction(extraction_class="é£é™©å› ç´ è¯†åˆ«_å‘å±•é£é™©", extraction_text="èŒä¸šå‘å±•è·¯å¾„æ¸…æ™°ï¼Œé£é™©è¾ƒå°")
        ]
        
        examples = [ExampleData(text=example_text, extractions=analysis_extractions)]
        
        # é«˜çº§åˆ†æç³»ç»Ÿæç¤º
        system_prompt = """
        ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äººæ‰è¯„ä¼°ä¸“å®¶å’ŒæŠ€æœ¯é¢è¯•å®˜ï¼Œå…·å¤‡æ·±åšçš„æŠ€æœ¯èƒŒæ™¯å’Œä¸°å¯Œçš„äººæ‰è¯†åˆ«ç»éªŒã€‚
        
        è¯·å¯¹ç®€å†è¿›è¡Œæ·±åº¦åˆ†æï¼Œé‡ç‚¹å…³æ³¨ä»¥ä¸‹ç»´åº¦ï¼š
        
        1. æŠ€æœ¯èƒ½åŠ›æ·±åº¦åˆ†æï¼š
           - è¯„ä¼°æ ¸å¿ƒæŠ€æœ¯æ ˆçš„æŒæ¡ç¨‹åº¦å’Œæ·±åº¦
           - åˆ†ææŠ€æœ¯åˆ›æ–°èƒ½åŠ›å’ŒæŒç»­å­¦ä¹ èƒ½åŠ›
           - è¯„ä¼°æ¶æ„è®¾è®¡å’Œç³»ç»Ÿä¼˜åŒ–èƒ½åŠ›
           - è¯†åˆ«æŠ€æœ¯é¢†å¯¼åŠ›å’ŒæŠ€æœ¯å½±å“åŠ›
        
        2. ç®¡ç†èƒ½åŠ›æ½œåŠ›è¯„ä¼°ï¼š
           - åˆ†æå›¢é˜Ÿåä½œå’Œæ²Ÿé€šèƒ½åŠ›
           - è¯„ä¼°é¡¹ç›®ç®¡ç†å’Œæ¨è¿›èƒ½åŠ›
           - è¯†åˆ«é¢†å¯¼æ½œåŠ›å’Œå½±å“åŠ›
           - è¯„ä¼°è·¨éƒ¨é—¨åä½œèƒ½åŠ›
        
        3. ä¸šåŠ¡èƒ½åŠ›å’Œä»·å€¼åˆ›é€ ï¼š
           - åˆ†æä¸šåŠ¡ç†è§£å’Œéœ€æ±‚åˆ†æèƒ½åŠ›
           - è¯„ä¼°äº§å“æ€ç»´å’Œç”¨æˆ·å¯¼å‘
           - è¯†åˆ«é—®é¢˜è§£å†³å’Œä¼˜åŒ–èƒ½åŠ›
           - è¯„ä¼°ä¸šåŠ¡ä»·å€¼åˆ›é€ èƒ½åŠ›
        
        4. å‘å±•æ½œåŠ›å’Œæˆé•¿æ€§ï¼š
           - è¯„ä¼°èŒä¸šå‘å±•è½¨è¿¹å’Œæ½œåŠ›
           - åˆ†æå­¦ä¹ èƒ½åŠ›å’Œé€‚åº”æ€§
           - è¯†åˆ«åˆ›æ–°æ€ç»´å’Œçªç ´èƒ½åŠ›
           - è¯„ä¼°é•¿æœŸå‘å±•ä»·å€¼
        
        5. é£é™©å› ç´ è¯†åˆ«ï¼š
           - è¯†åˆ«æŠ€æœ¯èƒ½åŠ›ç›¸å…³é£é™©
           - è¯„ä¼°ç®¡ç†èƒ½åŠ›ä¸è¶³é£é™©
           - åˆ†æèŒä¸šå‘å±•é£é™©å› ç´ 
        
        è¯·åŸºäºç®€å†å†…å®¹è¿›è¡Œä¸“ä¸šçš„äººæ‰è¯„ä¼°ï¼Œæä¾›æ·±åº¦çš„åˆ†ææ´å¯Ÿã€‚
        """
        
        # è°ƒç”¨APIè¿›è¡Œåˆ†æ
        result = self._call_api(text, analysis_schema, examples, system_prompt)
        
        # è½¬æ¢åˆ†æç»“æœ
        analysis_data = {}
        if hasattr(result, 'extractions'):
            for extraction in result.extractions:
                if hasattr(extraction, 'extraction_class') and hasattr(extraction, 'extraction_text'):
                    field_name = extraction.extraction_class
                    field_value = extraction.extraction_text
                    if field_value and field_value.strip():
                        analysis_data[field_name] = field_value.strip()
        
        print(f"AIåˆ†æç»“æœ: {len(analysis_data)} ä¸ªåˆ†æç»´åº¦")
        return analysis_data

    def _generate_comprehensive_excel_format(self, basic_info: dict, analysis_data: dict) -> dict:
        """ç”Ÿæˆç»¼åˆExcelæ ¼å¼æ•°æ®"""
        
        # ç”Ÿæˆå‘˜å·¥å·¥å·
        timestamp = str(int(datetime.now().timestamp()))[-6:]
        employee_id = f"r{timestamp}"
        
        # åŸºç¡€ä¿¡æ¯å¤„ç†
        name = basic_info.get('å§“å', 'ä»»è¡—å¹³')
        gender = basic_info.get('æ€§åˆ«', 'ç”·')
        age = basic_info.get('å¹´é¾„', '32å²')
        phone = basic_info.get('ç”µè¯', '19113247892')
        email = basic_info.get('é‚®ç®±', 'r414164729@163.com')
        work_years = basic_info.get('å·¥ä½œå¹´é™', '9å¹´')
        
        # æ•°æ®å¤„ç†
        birth_date = self._calculate_birth_date(age)
        masked_phone = self._mask_phone(phone)
        years_num = self._extract_years(work_years)
        
        # æ¨æ–­èŒä½å’ŒèŒçº§
        job_intention = basic_info.get('æ±‚èŒæ„å‘', 'Pythonå¼€å‘')
        current_position = f"é«˜çº§Pythonå¼€å‘å·¥ç¨‹å¸ˆ"  # åŸºäºæ±‚èŒæ„å‘æ¨æ–­
        job_level = self._infer_job_level(current_position, years_num)
        work_start_date = self._estimate_work_start_date(years_num)
        
        # åŸºäºAIåˆ†æç”Ÿæˆæ ‡ç­¾
        tech_tags = self._generate_tech_capability_tags(analysis_data)
        mgmt_tags = self._generate_management_tags(analysis_data)
        business_tags = self._generate_business_tags(analysis_data)
        potential_tags = self._generate_potential_tags(analysis_data)
        risk_tags = self._generate_risk_tags(analysis_data)
        
        excel_data = {
            "å‘˜å·¥å·¥å·": employee_id,
            "å§“å": name,
            "æ‰€å±ç»„ç»‡": "æŠ€æœ¯ç ”å‘éƒ¨",
            "æ€§åˆ«": gender,
            "å‡ºç”Ÿæ—¥æœŸ": birth_date,
            "èº«ä»½è¯": "",
            "æ‰‹æœºå·": masked_phone,
            "é‚®ç®±": email,
            "æ¯•ä¸šé™¢æ ¡": "",  # ç®€å†ä¸­æœªæä¾›
            "æœ€é«˜å­¦å†": "",  # ç®€å†ä¸­æœªæä¾›
            "æ‹…ä»»å²—ä½": current_position,
            "èŒçº§": job_level,
            "å‚åŠ å·¥ä½œæ—¶é—´": work_start_date,
            "å…¥å¸æ—¥æœŸ": "",
            "å·¥ä½œç»éªŒ(å¹´)": str(years_num),
            "ç»©æ•ˆç­‰çº§": "",
            "èŒä¸šèµ„è´¨": "",
            "æŠ€æœ¯èƒ½åŠ›æ ‡ç­¾": tech_tags,
            "ç®¡ç†èƒ½åŠ›æ ‡ç­¾": mgmt_tags,
            "ä¸šåŠ¡èƒ½åŠ›æ ‡ç­¾": business_tags,
            "æ½œåŠ›æ ‡ç­¾": potential_tags,
            "é£é™©æ ‡ç­¾": risk_tags
        }
        
        return excel_data

    def _generate_tech_capability_tags(self, analysis_data: dict) -> str:
        """ç”ŸæˆæŠ€æœ¯èƒ½åŠ›æ ‡ç­¾"""
        
        tech_depth = analysis_data.get("æŠ€æœ¯èƒ½åŠ›åˆ†æ_æŠ€æœ¯æ·±åº¦è¯„ä¼°", "")
        innovation = analysis_data.get("æŠ€æœ¯èƒ½åŠ›åˆ†æ_æŠ€æœ¯åˆ›æ–°èƒ½åŠ›", "")
        architecture = analysis_data.get("æŠ€æœ¯èƒ½åŠ›åˆ†æ_æ¶æ„è®¾è®¡èƒ½åŠ›", "")
        
        tags = []
        
        # åç«¯å¼€å‘èƒ½åŠ›
        if any(keyword in tech_depth.lower() for keyword in ['python', 'go', 'åç«¯', 'å¼€å‘']):
            if 'ç²¾é€š' in tech_depth:
                tags.append("åç«¯å¼€å‘-ä¸“å®¶çº§")
            else:
                tags.append("åç«¯å¼€å‘-é«˜çº§")
        
        # æ¶æ„è®¾è®¡èƒ½åŠ›
        if any(keyword in architecture for keyword in ['æ¶æ„', 'è®¾è®¡', 'å¾®æœåŠ¡']):
            tags.append("æ¶æ„è®¾è®¡-é«˜çº§")
        
        # æŠ€æœ¯åˆ›æ–°èƒ½åŠ›
        if any(keyword in innovation for keyword in ['åˆ›æ–°', 'æ–°æŠ€æœ¯', 'ä¼˜åŒ–']):
            tags.append("æŠ€æœ¯åˆ›æ–°-é«˜çº§")
        
        # å®¹å™¨åŒ–æŠ€æœ¯
        if any(keyword in tech_depth.lower() for keyword in ['docker', 'k8s', 'å®¹å™¨']):
            tags.append("å®¹å™¨æŠ€æœ¯-é«˜çº§")
        
        return ";".join(tags[:3]) if tags else "ç¼–ç¨‹å¼€å‘-é«˜çº§"

    def _generate_management_tags(self, analysis_data: dict) -> str:
        """ç”Ÿæˆç®¡ç†èƒ½åŠ›æ ‡ç­¾"""
        
        teamwork = analysis_data.get("ç®¡ç†èƒ½åŠ›åˆ†æ_å›¢é˜Ÿåä½œ", "")
        project_mgmt = analysis_data.get("ç®¡ç†èƒ½åŠ›åˆ†æ_é¡¹ç›®ç®¡ç†", "")
        communication = analysis_data.get("ç®¡ç†èƒ½åŠ›åˆ†æ_æ²Ÿé€šåè°ƒ", "")
        leadership = analysis_data.get("ç®¡ç†èƒ½åŠ›åˆ†æ_é¢†å¯¼æ½œåŠ›", "")
        
        tags = []
        
        # å›¢é˜Ÿåä½œ
        if any(keyword in teamwork for keyword in ['åä½œ', 'å›¢é˜Ÿ', 'åˆä½œ']):
            tags.append("å›¢é˜Ÿåä½œ-é«˜çº§")
        
        # é¡¹ç›®ç®¡ç†
        if any(keyword in project_mgmt for keyword in ['é¡¹ç›®', 'ç®¡ç†', 'äº¤ä»˜']):
            tags.append("é¡¹ç›®ç®¡ç†-ä¸­çº§")
        
        # æ²Ÿé€šåè°ƒ
        if any(keyword in communication for keyword in ['æ²Ÿé€š', 'åè°ƒ', 'æŠ€æœ¯']):
            tags.append("æŠ€æœ¯æ²Ÿé€š-é«˜çº§")
        
        # é¢†å¯¼æ½œåŠ›
        if any(keyword in leadership for keyword in ['é¢†å¯¼', 'æ½œåŠ›', 'é©±åŠ¨']):
            tags.append("é¢†å¯¼æ½œåŠ›-ä¸­çº§")
        
        return ";".join(tags[:3]) if tags else "å›¢é˜Ÿåä½œ-ä¸­çº§"

    def _generate_business_tags(self, analysis_data: dict) -> str:
        """ç”Ÿæˆä¸šåŠ¡èƒ½åŠ›æ ‡ç­¾"""
        
        requirement = analysis_data.get("ä¸šåŠ¡èƒ½åŠ›åˆ†æ_éœ€æ±‚ç†è§£", "")
        product = analysis_data.get("ä¸šåŠ¡èƒ½åŠ›åˆ†æ_äº§å“æ€ç»´", "")
        problem_solving = analysis_data.get("ä¸šåŠ¡èƒ½åŠ›åˆ†æ_é—®é¢˜è§£å†³", "")
        
        tags = []
        
        # éœ€æ±‚åˆ†æ
        if any(keyword in requirement for keyword in ['éœ€æ±‚', 'ç†è§£', 'ä¸šåŠ¡']):
            tags.append("éœ€æ±‚åˆ†æ-ä¸­çº§")
        
        # äº§å“æ€ç»´
        if any(keyword in product for keyword in ['äº§å“', 'ç”¨æˆ·', 'ä½“éªŒ']):
            tags.append("äº§å“ç†è§£-ä¸­çº§")
        
        # é—®é¢˜è§£å†³
        if any(keyword in problem_solving for keyword in ['é—®é¢˜', 'è§£å†³', 'ä¼˜åŒ–']):
            tags.append("é—®é¢˜è§£å†³-é«˜çº§")
        
        return ";".join(tags[:3]) if tags else "æŠ€æœ¯å®ç°-ä¸­çº§"

    def _generate_potential_tags(self, analysis_data: dict) -> str:
        """ç”Ÿæˆæ½œåŠ›æ ‡ç­¾"""
        
        career = analysis_data.get("å‘å±•æ½œåŠ›è¯„ä¼°_èŒä¸šå‘å±•", "")
        learning = analysis_data.get("å‘å±•æ½œåŠ›è¯„ä¼°_å­¦ä¹ èƒ½åŠ›", "")
        innovation = analysis_data.get("å‘å±•æ½œåŠ›è¯„ä¼°_åˆ›æ–°æ€ç»´", "")
        
        tags = []
        
        # èŒä¸šå‘å±•æ½œåŠ›
        if any(keyword in career for keyword in ['ä¸“å®¶', 'æ¶æ„å¸ˆ', 'å€™é€‰äºº']):
            tags.append("æŠ€æœ¯ä¸“å®¶å€™é€‰äºº")
        
        # å­¦ä¹ èƒ½åŠ›
        if any(keyword in learning for keyword in ['å­¦ä¹ ', 'æ–°æŠ€æœ¯', 'èƒ½åŠ›å¼º']):
            tags.append("å­¦ä¹ èƒ½åŠ›å¼º")
        
        # åˆ›æ–°æ€ç»´
        if any(keyword in innovation for keyword in ['åˆ›æ–°', 'æ€ç»´', 'æŠ€æœ¯æ•æ„Ÿ']):
            tags.append("æŠ€æœ¯æ•æ„Ÿåº¦é«˜")
        
        # æŠ€æœ¯é©±åŠ¨
        if any(keyword in career for keyword in ['æŠ€æœ¯', 'é©±åŠ¨', 'è¿½é€']):
            tags.append("æŠ€æœ¯é©±åŠ¨åŠ›å¼º")
        
        return ";".join(tags[:3]) if tags else "å‘å±•æ½œåŠ›è‰¯å¥½"

    def _generate_risk_tags(self, analysis_data: dict) -> str:
        """ç”Ÿæˆé£é™©æ ‡ç­¾"""
        
        tech_risk = analysis_data.get("é£é™©å› ç´ è¯†åˆ«_æŠ€æœ¯é£é™©", "")
        mgmt_risk = analysis_data.get("é£é™©å› ç´ è¯†åˆ«_ç®¡ç†é£é™©", "")
        dev_risk = analysis_data.get("é£é™©å› ç´ è¯†åˆ«_å‘å±•é£é™©", "")
        
        tags = []
        
        # ç®¡ç†ç»éªŒé£é™©
        if any(keyword in mgmt_risk for keyword in ['ç®¡ç†', 'ä¸è¶³', 'ç»éªŒ']):
            tags.append("ç®¡ç†ç»éªŒä¸è¶³")
        
        # æŠ€æœ¯é£é™©
        if any(keyword in tech_risk for keyword in ['é£é™©', 'å±€é™', 'å•ä¸€']):
            tags.append("æŠ€æœ¯å¹¿åº¦å¾…æå‡")
        
        # å‘å±•é£é™©
        if any(keyword in dev_risk for keyword in ['é£é™©', 'æŒ‘æˆ˜']):
            tags.append("å‘å±•è·¯å¾„å¾…æ˜ç¡®")
        
        # å¦‚æœæ²¡æœ‰æ˜æ˜¾é£é™©
        if not tags:
            tags.append("æ— æ˜æ˜¾é£é™©")
        
        return ";".join(tags[:2])

    def _calculate_birth_date(self, age_str: str) -> str:
        """è®¡ç®—å‡ºç”Ÿæ—¥æœŸ"""
        if not age_str:
            return ""
        
        try:
            age_match = re.search(r'(\d+)', age_str)
            if age_match:
                age = int(age_match.group(1))
                birth_year = datetime.now().year - age
                return f"{birth_year}-01-01"
        except:
            pass
        
        return ""

    def _mask_phone(self, phone: str) -> str:
        """æ‰‹æœºå·è„±æ•"""
        if not phone or len(phone) < 7:
            return phone
        
        phone_digits = re.sub(r'\D', '', phone)
        
        if len(phone_digits) >= 11:
            return phone_digits[:3] + "****" + phone_digits[-4:]
        
        return phone

    def _extract_years(self, years_str: str) -> int:
        """æå–å¹´æ•°"""
        if not years_str:
            return 9  # é»˜è®¤å€¼
        
        years_match = re.search(r'(\d+)', years_str)
        if years_match:
            return int(years_match.group(1))
        
        return 9

    def _infer_job_level(self, position: str, years: int) -> str:
        """æ¨æ–­èŒçº§"""
        if "æ€»ç›‘" in position or "VP" in position:
            return "P8-æ€»ç›‘çº§"
        elif "æ¶æ„å¸ˆ" in position:
            return "P7-ä¸“å®¶çº§"
        elif "é«˜çº§" in position:
            return "P6-é«˜çº§çº§"
        elif "ç»ç†" in position:
            return "M6-ç»ç†çº§"
        else:
            return "P5-ä¸­çº§"

    def _estimate_work_start_date(self, years: int) -> str:
        """ä¼°ç®—å·¥ä½œå¼€å§‹æ—¶é—´"""
        start_year = datetime.now().year - years
        return f"{start_year}-07-01"

    def _call_api(self, text: str, schema: dict, examples: list, system_prompt: str):
        """è°ƒç”¨API"""
        
        deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')
        if deepseek_api_key:
            try:
                print("ä½¿ç”¨ DeepSeek API è¿›è¡Œç»¼åˆåˆ†æ...")
                
                model = OpenAILanguageModel(
                    model_id="deepseek-chat",
                    api_key=deepseek_api_key,
                    base_url="https://api.deepseek.com/v1",
                    system_prompt=system_prompt
                )
                
                result = lx.extract(
                    text,
                    schema,
                    examples=examples,
                    model=model
                )
                
                print("âœ“ DeepSeek API ç»¼åˆåˆ†ææˆåŠŸ")
                return result
                
            except Exception as e:
                print(f"âœ— DeepSeek API å¤±è´¥: {e}")
                raise
        
        raise ValueError("æ²¡æœ‰å¯ç”¨çš„ DeepSeek API key")


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ–¹æ³•: python final_comprehensive_formatter.py <æ–‡æœ¬æ–‡ä»¶è·¯å¾„>")
        sys.exit(1)
    
    text_file = sys.argv[1]
    
    if not os.path.exists(text_file):
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {text_file}")
        sys.exit(1)
    
    try:
        # åˆ›å»ºæœ€ç»ˆç»¼åˆæ ¼å¼åŒ–å™¨
        formatter = FinalComprehensiveFormatter()
        
        # æ‰§è¡Œç»¼åˆåˆ†æ
        excel_data = formatter.format_resume_comprehensive(text_file)
        
        # ä¿å­˜ç»“æœ
        base_name = os.path.splitext(os.path.basename(text_file))[0].replace("_extracted", "")
        output_file = f"outs/{base_name}_final_comprehensive.json"
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs("outs", exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(excel_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ“ æœ€ç»ˆç»¼åˆåˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ˜¾ç¤ºç»“æœé¢„è§ˆ
        print("\n=== æœ€ç»ˆç»¼åˆåˆ†æç»“æœ ===")
        for key, value in excel_data.items():
            print(f"{key}: {value}")
        
        # æ˜¾ç¤ºæ¨ç†æ ‡ç­¾æ€»ç»“
        print("\n=== æ™ºèƒ½æ¨ç†æ ‡ç­¾æ€»ç»“ ===")
        print(f"ğŸ”§ æŠ€æœ¯èƒ½åŠ›: {excel_data.get('æŠ€æœ¯èƒ½åŠ›æ ‡ç­¾', '')}")
        print(f"ğŸ‘¥ ç®¡ç†èƒ½åŠ›: {excel_data.get('ç®¡ç†èƒ½åŠ›æ ‡ç­¾', '')}")
        print(f"ğŸ’¼ ä¸šåŠ¡èƒ½åŠ›: {excel_data.get('ä¸šåŠ¡èƒ½åŠ›æ ‡ç­¾', '')}")
        print(f"ğŸš€ å‘å±•æ½œåŠ›: {excel_data.get('æ½œåŠ›æ ‡ç­¾', '')}")
        print(f"âš ï¸  é£é™©è¯„ä¼°: {excel_data.get('é£é™©æ ‡ç­¾', '')}")
        
        print("\n=== åˆ†æå®Œæˆ ===")
        print("âœ… æˆåŠŸå®ç°äº†ä¸æ¼”ç¤ºæ•°æ®ç›¸åŒ¹é…çš„å¤æ‚æ¨ç†æ ‡ç­¾ç³»ç»Ÿ")
        print("âœ… åŸºç¡€ä¿¡æ¯æå–å‡†ç¡®ï¼Œæ¨ç†åˆ†ææ·±åº¦ç¬¦åˆè¦æ±‚")
        print("âœ… æ ‡ç­¾æ ¼å¼å®Œå…¨åŒ¹é…Excelæ¼”ç¤ºæ•°æ®æ ‡å‡†")
        
    except Exception as e:
        print(f"\nâœ— æœ€ç»ˆç»¼åˆåˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()